version: '3.8'

services:
  crawl4ai:
    build:
      context: ../..
      dockerfile: deploy/dokploy/Dockerfile
    ports:
      - "11235:11235"
    environment:
      # LLM Provider Keys - Set these in Dokploy environment variables
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - TOGETHER_API_KEY=${TOGETHER_API_KEY}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - GEMINI_API_TOKEN=${GEMINI_API_TOKEN}
      
      # Application configuration
      - PYTHON_ENV=production
      
      # Redis configuration (using internal Redis)
      - REDIS_HOST=localhost
      - REDIS_PORT=6379
    volumes:
      - /dev/shm:/dev/shm  # Chromium performance
      - crawl4ai_data:/app/downloads  # Persistent storage for downloads
      - crawl4ai_logs:/app/logs       # Persistent storage for logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  crawl4ai_data:
    driver: local
  crawl4ai_logs:
    driver: local
